{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUZFC2hBNlYM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(style='seaborn')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvmmK0_EVcsQ",
        "outputId": "63d84715-3d4d-4f70-e0e5-259ef5cef811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        " \n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sk2V54PbSxl",
        "outputId": "55f73483-f08b-4216-9085-301d9f019fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stemming\n",
            "  Downloading stemming-1.0.1.zip (13 kB)\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-py3-none-any.whl size=11138 sha256=430128d35e3e75c7fad066b8f88dab27a9a0c300c8f4e5b5dabf2a0a19865526\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/e5/e2/c52ebc0a5b53fd82b00cc385e57bb1c90bd50e5f54ddbc06d1\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n"
          ]
        }
      ],
      "source": [
        "#removing punctuations\n",
        "#library that contains punctuation\n",
        "import string\n",
        "string.punctuation\n",
        "!pip install stemming\n",
        "from stemming.porter2 import stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQm5pgg5beT8"
      },
      "outputs": [],
      "source": [
        "#defining the function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "  if(type(text)==float):\n",
        "    return text\n",
        "  ans=\"\"  \n",
        "  for i in text:     \n",
        "    if i not in string.punctuation:\n",
        "      ans+=i    \n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-0bMcjnbf1-"
      },
      "outputs": [],
      "source": [
        "def generate_Ngrams(text,ngram=1):\n",
        "  word1=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))] \n",
        "  words=[] \n",
        "  for i in word1:\n",
        "    words.append(lemmatizer.lemmatize(stem(i)))\n",
        "  # print(\"Sentence after removing stopwords:\",word1)\n",
        "  # print(\"Sentence after Stemming and Lemmatization:\",words)\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcko5TTGbnjF",
        "outputId": "d96cd35f-d005-44e8-83fe-d91b0a2336f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['I student', 'student IIT', 'IIT Gandhinagar'],\n",
              " ['I studi', 'studi IIT', 'IIT Gandhinagar', 'Gandhinagar 3', '3 year']]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l1=[]\n",
        "l1.append(generate_Ngrams(\"I am a student of IIT Gandhinagar\",2))\n",
        "l1.append(generate_Ngrams(\"I have been studying in IIT Gandhinagar for 3 years\",2))\n",
        "l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVcqqFTqfa21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHL7CAzZekUf"
      },
      "outputs": [],
      "source": [
        "from operator import eq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WrUbCKniiPb",
        "outputId": "24b02a8f-b29a-46b9-8e70-d6d94f91a3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=b6e04389780843d5792e18943dadaca382edbd7f9620e43465219f081c06a600\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJPa8zbCOM2o"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "result1 = wikipedia.search(\"Neural Networks\")\n",
        "result2 = wikipedia.search(\"Neurons\")\n",
        "# result3=wikipedia.search(\"Chris\")\n",
        "result = result1+result2#+result3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeKANSWCQrye",
        "outputId": "09fe20b4-7f48-4976-fa75-0b1274e93a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Neuron', 'Mirror neuron', 'Motor neuron', 'Cerebral cortex', 'Sensory neuron', 'Artificial neuron', 'Action potential', 'Artificial neural network', 'Nervous system', 'Motor neuron disease']\n"
          ]
        }
      ],
      "source": [
        "print(result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yve3HPKWQwce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt15aSRXTi1O"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "  if(type(text)==float):\n",
        "    return text\n",
        "  ans=\"\"  \n",
        "  for i in text:     \n",
        "    if i not in string.punctuation:\n",
        "      ans+=i    \n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECWjAdhfRMgW"
      },
      "outputs": [],
      "source": [
        "page = wikipedia.page(result[0])\n",
        "content = page.content\n",
        "content_list = content.split(\"\\n\")\n",
        "# print(content_list)\n",
        "final_content_list = []\n",
        "for i in range (len(content_list)):\n",
        "  if content_list[i] and len(content_list[i].split(\" \")) > 30:\n",
        "    final_content_list.append(content_list[i])\n",
        "# print(len(final_content_list))\n",
        "# print(final_content_list)\n",
        "final_list=[]\n",
        "for i in final_content_list: \n",
        "  final_list.append(remove_punctuation(i))\n",
        "# print(len(final_list))\n",
        "# print(final_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rohqz6iajKmJ",
        "outputId": "3350360e-0028-46d7-8184-e72c91852eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A neural network is a network or circuit of biological neurons or in a modern sense an artificial neural network composed of artificial neurons or nodes Thus a neural network is either a biological neural network made up of biological neurons or an artificial neural network used for solving artificial intelligence AI problems The connections of the biological neuron are modeled in artificial neural networks as weights between nodes A positive weight reflects an excitatory connection while negative values mean inhibitory connections All inputs are modified by a weight and summed This activity is referred to as a linear combination Finally an activation function controls the amplitude of the output For example an acceptable range of output is usually between 0 and 1 or it could be âˆ’1 and 1\n",
            "35\n"
          ]
        }
      ],
      "source": [
        "print(final_list[0])\n",
        "print(len(final_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJOIHDhEUTJl"
      },
      "outputs": [],
      "source": [
        "def calculator(l1):\n",
        "  n=len(l1)\n",
        "  m = np.zeros((n+1,n+1)) # numpy.zeros(shape, dtype = None, order = 'C')\n",
        "  n=len(l1)\n",
        "  for i in range(n):\n",
        "    for j in range(i+1,n):\n",
        "      list1=l1[i]\n",
        "      list2=l1[j]\n",
        "      # print(list1,list2)\n",
        "      c=list(set(list1) & set(list2))\n",
        "      res=len(c)\n",
        "      num=max(len(list1),len(list2))\n",
        "      res = res/num\n",
        "      m[i][j]=res\n",
        "      m[j][i]=res\n",
        "  return m\n",
        "\n",
        "def CalMatrix(final_list):\n",
        "  n=len(final_list)\n",
        "  # print(n)\n",
        "  Ngram_list=[]\n",
        "\n",
        "  for i in final_list:\n",
        "    Ngram_list.append(generate_Ngrams(i,3))\n",
        "    # print(Ngram_list)\n",
        "   \n",
        "  return calculator(Ngram_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWanuwdFUXQb"
      },
      "outputs": [],
      "source": [
        "Matrix=CalMatrix(final_list)\n",
        "# Matrix[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1yxqkLMfLjj"
      },
      "outputs": [],
      "source": [
        "def order_det(Matrix):\n",
        "  final_order_lst = [0]\n",
        "  order_lst1 = [0]\n",
        "  order_lst2 = [0]\n",
        "  for i in range(Matrix.shape[0]):\n",
        "    # sorted_list = []\n",
        "    # sorted_list = Matrix[i].sort\n",
        "    sorted_tuples = []\n",
        "    # print(Matrix)\n",
        "    sorted_tuples = sorted(enumerate(Matrix[final_order_lst[-1]]), key=lambda i: i[1])\n",
        "    # print(sorted_tuples)\n",
        "    for elem in sorted_tuples[::-1]:\n",
        "      if elem[0] not in order_lst1:\n",
        "        order_lst1.append(elem[0])\n",
        "        prob1 = elem[1]\n",
        "        break\n",
        "      \n",
        "    for elem in sorted_tuples[::-1]:\n",
        "      if elem[0] not in order_lst2 and elem[0]!=order_lst1[-1]:\n",
        "        order_lst2.append(elem[0])\n",
        "        prob2 = elem[1]\n",
        "        break\n",
        "    \n",
        "    sorted_tuples1 = sorted(enumerate(Matrix[order_lst1[-1]]), key = lambda i: i[1])\n",
        "    sorted_tuples2 = sorted(enumerate(Matrix[order_lst2[-1]]), key = lambda i: i[1])\n",
        "\n",
        "    for elem in sorted_tuples1[::-1]:\n",
        "      if elem[0] not in order_lst1:\n",
        "        order_lst1.append(elem[0])\n",
        "        prob11 = elem[1]\n",
        "        break\n",
        "\n",
        "    for elem in sorted_tuples[::-1]:\n",
        "      if elem[0] not in order_lst2 and elem[0]!=order_lst1[-1]:\n",
        "        order_lst2.append(elem[0])\n",
        "        prob22 = elem[1]\n",
        "        break\n",
        "\n",
        "    prob_1 = prob1 + prob11\n",
        "    prob_2 = prob2 + prob22\n",
        "\n",
        "    if prob_1 > prob_2:\n",
        "      final_order_lst = order_lst1[:-1:]\n",
        "\n",
        "    else:\n",
        "      final_order_lst = order_lst2[:-1:]\n",
        "    # print(order_lst)\n",
        "    # break\n",
        "\n",
        "  return (final_order_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHKXhfYUjhOw"
      },
      "outputs": [],
      "source": [
        "def Ordered_output(final_order_lst,final_content_list):\n",
        "  output_list=[]\n",
        "  for i in final_order_lst:\n",
        "    output_list.append(final_content_list[i])\n",
        "  return output_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VjR68Dch3DK"
      },
      "outputs": [],
      "source": [
        "def accuracy(lst):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for i in range(len(lst)-1):\n",
        "    if (lst[i+1] - lst[i] == 1):\n",
        "      correct+=1\n",
        "    total+=1\n",
        "  return correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5ast5nYmq_c"
      },
      "outputs": [],
      "source": [
        "def PageOrder(result):\n",
        "  sze=len(result)\n",
        "  AccuracyLst=[]\n",
        "  MatrixLst=[]\n",
        "  Order_List=[]\n",
        "  Page_list=[]\n",
        "  for i in range(sze):\n",
        "    page = wikipedia.page(result[i])\n",
        "    content = page.content\n",
        "    content_list = content.split(\"\\n\")\n",
        "    # print(content_list)\n",
        "    final_content_list = []\n",
        "    for i in range (len(content_list)):\n",
        "      if content_list[i] and len(content_list[i].split(\" \")) > 30:\n",
        "        final_content_list.append(content_list[i])\n",
        "    # print(len(final_content_list))\n",
        "    # print(final_content_list)\n",
        "    final_list=[]\n",
        "    for i in final_content_list: \n",
        "      final_list.append(remove_punctuation(i))\n",
        "    # print(len(final_list))\n",
        "    # print(final_list[0])\n",
        "    Matrix=CalMatrix(final_list)\n",
        "    MatrixLst.append(Matrix)\n",
        "    olst=order_det(Matrix)\n",
        "    Order_List.append(olst)\n",
        "    Optlst=Ordered_output(olst,final_content_list) \n",
        "    Page_list.append(Optlst)\n",
        "    Acc_score=accuracy(olst)\n",
        "    AccuracyLst.append(Acc_score)\n",
        "  return AccuracyLst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8yg7Rh6uLYQ"
      },
      "outputs": [],
      "source": [
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4CJMQLznnjS",
        "outputId": "856854e1-b709-4788-afe3-ca46257b8e33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.16508747230408333"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Alist=PageOrder(result)\n",
        "Average(Alist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZT3nMLBtIRa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ReadingOrderDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
